# Awesome-Minecraft-Agents

---
<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Policy](#awesome-policy)
  - [Vision-driven Policy](#vision-driven-policy)
  - [Goal-conditioned Policy](#goal-conditioned-policy)
  
- [Awesome Agent](#awesome-agents)
  - [Action-based Agent](#action-based-agent)
  - [Code-based Agent](#code-based-agent)

---

# Awesome Policy

## Vision-driven Policy
|  Title  |   Venue  |   Year   |   Code   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/openai/Video-Pre-Training.svg?style=social&label=Star) <br> [**Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos**](https://arxiv.org/abs/2206.11795) <br> | NeurIPS | 2022 | [Github](https://github.com/openai/Video-Pre-Training) | - | 

## Goal-conditioned Policy
|  Title  |   Venue  |   Year   |   Code   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/MineDojo/MineDojo.svg?style=social&label=Star) <br> [**MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge**](https://arxiv.org/abs/2206.08853) <br> | NeurIPS | 2022 | [Github](https://github.com/MineDojo/MineDojo) | [Demo](https://minedojo.org/) |
| ![Star](https://img.shields.io/github/stars/Shalev-Lifshitz/STEVE-1.svg?style=social&label=Star) <br> [**STEVE-1: A Generative Model for Text-to-Behavior in Minecraft**](https://arxiv.org/abs/2306.00937) <br> | NeurIPS | 2023 | [Github](https://github.com/Shalev-Lifshitz/STEVE-1) | [Demo](https://sites.google.com/view/steve-1) |
| ![Star](https://img.shields.io/github/stars/CraftJarvis/GROOT.svg?style=social&label=Star) <br> [**GROOT: Learning to Follow Instructions by Watching Gameplay Videos**](https://arxiv.org/abs/2310.08235) <br> | ICLR | 2024 | [Github](https://github.com/CraftJarvis/GROOT) | [Demo](https://craftjarvis.github.io/GROOT/)| 

---

# Awesome Agent

## Action-based Agent
|  Title  |   Venue  |   Year  |   Code   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/Vision-CAIR/LongVU.svg?style=social&label=Star) <br> [**LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding**](https://arxiv.org/pdf/2410.17434) <br> | arXiv | 2024-10-22 | [Github](https://github.com/Vision-CAIR/LongVU) | [Demo](https://huggingface.co/spaces/Vision-CAIR/LongVU) |
| ![Star](https://img.shields.io/github/stars/shikiw/Modality-Integration-Rate.svg?style=social&label=Star) <br> [**Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate**](https://arxiv.org/pdf/2410.07167) <br> | arXiv | 2024-10-09 | [Github](https://github.com/shikiw/Modality-Integration-Rate) | - |
| ![Star](https://img.shields.io/github/stars/VT-NLP/MultiInstruct.svg?style=social&label=Star) <br> [**MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning**](https://arxiv.org/pdf/2212.10773.pdf) <br> | ACL | 2022-12-21 | [Github](https://github.com/VT-NLP/MultiInstruct) | - | 

## Code-based Agent
|  Title  |   Venue  |   Year   |   Code   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/MineDojo/Voyager.svg?style=social&label=Star) <br> [**Voyager: An Open-Ended Embodied Agent with Large Language Models**](https://arxiv.org/abs/2305.16291) <br> |  NeurIPS | 2023 | [Github](https://github.com/MineDojo/Voyager) | [Demo](https://voyager.minedojo.org/) |

